* Project set-up
** Directories
Scripts are in scripts, analysis contains mostly files generated by tools such as multiqc, data contains raw, intermediate data and counts.
** Steps
The steps of the pipeline are as follow :
1. Download with =prefetch= and decompress with =fastq-dump=
2. Quality control with =fastqc= and =multiqc=
3. Adapter trimming with =cutadapt= (and re - =fastqc=)
4. Pseudo-mapping and quantification with =salmon=
5. Importation/transcript quantification are done with =tximeta=
6. DEG analysis with =DESeq2=
7. Clustering analysis with =WGCNA=
** Workflow tools
- steps 2-3-4 are performed via =Snakemake=
- steps 5-6 through a =shiny= interface
  
* Running instructions

** From raw data (reads)
1. Clone this repository
2. Install [[https://github.com/conda-forge/miniforge#mambaforge][Mambaforge]]
3. Run ~mamba env create --name name_of_env --file salmon_env.yaml~ in a terminal
4. Run ~conda activate name_of_env~
5. Edit the config file (for instance for single-end or pair-end data)
6. Run ~snakemake~
7. Quality control check in =./analysis=
8. Download the R packages needed (see sessionInfo.txt) (or open =scripts/global.R= in RStudio and download missing packages)
9. Run ~R -e "shiny::runApp('/scripts/shiny')"~ for the rest of the analysis


** From a raw counts table
1. Download the R packages needed (see sessionInfo.txt) (or open =scripts/global.R= in RStudio and download missing packages)
2. Run ~R -e "shiny::runApp('/scripts/shiny')"~ 
