* Project set-up
** Directories
Scripts are in scripts, analysis contain everything from raw counts,  also fastqc analysis, data contains raw and intermediate data.
** Steps
The steps of the pipeline are as follow :
1. Download with =prefetch= and decompress with =fastq-dump=
2. Quality control with =fastqc= and =multiqc=
3. Adapter trimming with =cutadapt= (and re - =fastqc=)
4. Pseudo-mapping with =salmon=



* Work in progress
1. Maybe think about piping cutadapt directly into salmon, as it will help alleviating the storage stress, and improve the pipeline's speed. The only disadvantage I see would be that I won't be able to run FastQC on cutadapt data (to my knowledge at least). So far, I'm not sure this step has been necessary, so... But then the questions becomes : how do you do around piping paired end reads? It requires two input files, piping two streams into salmon which requires also two input files. 
2. 
